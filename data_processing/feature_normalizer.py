#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
特征归一化处理器 - 生成归一化特征数据表格

按照数据库三大范式设计，生成符合规范的归一化数据表格：
1. subjects.csv - 受试者基本信息
2. tasks.csv - 任务信息
3. mmse_scores.csv - MMSE评分
4. game_sessions.csv - 游戏会话信息
5. roi_features.csv - ROI特征
6. rqa_features.csv - RQA特征
7. normalized_features_summary.csv - 归一化特征汇总
"""

import pandas as pd
import numpy as np
import os
import json
from typing import Dict, List, Tuple
import glob
from pathlib import Path
import logging

# 配置日志
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FeatureNormalizer:
    """特征归一化处理器"""
    
    def __init__(self, data_root: str = "data", output_dir: str = "data/normalized_features"):
        self.data_root = data_root
        self.output_dir = output_dir
        self.normalization_config = None
        self.load_normalization_config()
        
        # 确保输出目录存在
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
    def load_normalization_config(self):
        """加载归一化配置"""
        config_file = "analysis_results/data_range_analysis.json"
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.normalization_config = data.get('normalization_config', {})
        else:
            logger.warning(f"归一化配置文件不存在: {config_file}")
            self.normalization_config = self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """获取默认归一化配置"""
        return {
            'features': {
                'game_duration': {'min_value': 0.0, 'max_value': 180.0},
                'roi_fixation_time': {'min_value': 0.0, 'max_value': 67.23},
                'RR-2D-xy': {'min_value': 0.0096, 'max_value': 0.2422},
                'RR-1D-x': {'min_value': 0.0298, 'max_value': 0.2870},
                'DET-2D-xy': {'min_value': 0.5808, 'max_value': 0.9655},
                'DET-1D-x': {'min_value': 0.5319, 'max_value': 0.9556},
                'ENT-2D-xy': {'min_value': 0.7219, 'max_value': 3.8210},
                'ENT-1D-x': {'min_value': 0.8879, 'max_value': 3.5615}
            }
        }
    
    def normalize_value(self, value: float, feature_name: str) -> float:
        """归一化单个值"""
        config = self.normalization_config['features'].get(feature_name, {})
        min_val = config.get('min_value', 0.0)
        max_val = config.get('max_value', 1.0)
        
        if max_val == min_val:
            return 0.0
        
        normalized = (value - min_val) / (max_val - min_val)
        return np.clip(normalized, 0.0, 1.0)\n    \n    def extract_subjects_info(self) -> pd.DataFrame:\n        \"\"\"提取受试者基本信息\"\"\"\n        logger.info(\"📊 提取受试者基本信息...\")\n        \n        subjects = []\n        \n        # 扫描校准数据目录\n        groups = ['ad_calibrated', 'mci_calibrated', 'control_calibrated']\n        group_mappings = {\n            'ad_calibrated': 'ad',\n            'mci_calibrated': 'mci', \n            'control_calibrated': 'control'\n        }\n        \n        for group_dir in groups:\n            group_path = os.path.join(self.data_root, group_dir)\n            if not os.path.exists(group_path):\n                continue\n                \n            group_type = group_mappings[group_dir]\n            \n            for group_folder in os.listdir(group_path):\n                folder_path = os.path.join(group_path, group_folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                \n                # 从文件夹名提取组号\n                if group_type == 'ad':\n                    group_number = group_folder.replace('ad_group_', '')\n                    subject_id = f'ad{group_number.zfill(2)}'\n                elif group_type == 'mci':\n                    group_number = group_folder.replace('mci_group_', '')\n                    subject_id = f'm{group_number.zfill(2)}'\n                else:  # control\n                    group_number = group_folder.replace('control_group_', '')\n                    subject_id = f'n{group_number.zfill(2)}'\n                \n                subjects.append({\n                    'subject_id': subject_id,\n                    'group_type': group_type,\n                    'group_number': int(group_number),\n                    'original_id': subject_id\n                })\n        \n        subjects_df = pd.DataFrame(subjects)\n        subjects_df = subjects_df.sort_values(['group_type', 'group_number'])\n        \n        logger.info(f\"✅ 提取了 {len(subjects_df)} 个受试者信息\")\n        return subjects_df\n    \n    def create_tasks_info(self) -> pd.DataFrame:\n        \"\"\"创建任务信息表\"\"\"\n        logger.info(\"📊 创建任务信息表...\")\n        \n        tasks = [\n            {'task_id': 'Q1', 'task_name': '第一题', 'max_duration_seconds': 180.0, 'description': 'VR-MMSE任务1'},\n            {'task_id': 'Q2', 'task_name': '第二题', 'max_duration_seconds': 180.0, 'description': 'VR-MMSE任务2'},\n            {'task_id': 'Q3', 'task_name': '第三题', 'max_duration_seconds': 180.0, 'description': 'VR-MMSE任务3'},\n            {'task_id': 'Q4', 'task_name': '第四题', 'max_duration_seconds': 180.0, 'description': 'VR-MMSE任务4'},\n            {'task_id': 'Q5', 'task_name': '第五题', 'max_duration_seconds': 180.0, 'description': 'VR-MMSE任务5'}\n        ]\n        \n        tasks_df = pd.DataFrame(tasks)\n        logger.info(f\"✅ 创建了 {len(tasks_df)} 个任务记录\")\n        return tasks_df\n    \n    def extract_mmse_scores(self) -> pd.DataFrame:\n        \"\"\"提取MMSE评分\"\"\"\n        logger.info(\"📊 提取MMSE评分...\")\n        \n        mmse_data = []\n        mmse_files = {\n            'ad': 'MMSE_Score/阿尔兹海默症组.csv',\n            'mci': 'MMSE_Score/轻度认知障碍组.csv', \n            'control': 'MMSE_Score/控制组.csv'\n        }\n        \n        for group_type, file_path in mmse_files.items():\n            full_path = os.path.join(self.data_root, file_path)\n            if not os.path.exists(full_path):\n                logger.warning(f\"MMSE文件不存在: {full_path}\")\n                continue\n            \n            try:\n                df = pd.read_csv(full_path)\n                \n                # 处理列名（可能有不同的格式）\n                subject_col = None\n                for col in df.columns:\n                    if '试者' in col or 'subject' in col.lower():\n                        subject_col = col\n                        break\n                \n                if not subject_col:\n                    logger.warning(f\"未找到受试者列: {full_path}\")\n                    continue\n                \n                for _, row in df.iterrows():\n                    original_id = str(row[subject_col]).strip()\n                    \n                    # 标准化subject_id\n                    if group_type == 'ad':\n                        subject_id = f\"ad{original_id.replace('ad', '').zfill(2)}\"\n                    elif group_type == 'mci':\n                        subject_id = f\"m{original_id.replace('M', '').replace('m', '').zfill(2)}\"\n                    else:  # control\n                        subject_id = f\"n{original_id.replace('n', '').zfill(2)}\"\n                    \n                    # VR-MMSE总分（基于各项得分求和）\n                    vr_mmse_score = 0\n                    score_columns = [col for col in df.columns if col != subject_col]\n                    \n                    orientation_time = 0\n                    orientation_place = 0\n                    immediate_memory = 0\n                    attention_calculation = 0\n                    delayed_recall = 0\n                    \n                    # 映射各项得分\n                    for col in score_columns:\n                        val = row[col] if pd.notna(row[col]) else 0\n                        vr_mmse_score += val\n                        \n                        # 根据列名分类（这需要根据实际列名调整）\n                        if '年' in col or '季' in col or '月' in col or '星期' in col or '日' in col:\n                            orientation_time += val\n                        elif '省' in col or '市' in col or '区' in col or '医院' in col or '楼层' in col:\n                            orientation_place += val\n                        elif '记忆' in col and ('即刻' in col or '立即' in col):\n                            immediate_memory += val\n                        elif '注意' in col or '计算' in col or '序列' in col:\n                            attention_calculation += val\n                        elif '延迟' in col or '回忆' in col:\n                            delayed_recall += val\n                    \n                    # VR-MMSE (21分) 转 标准MMSE (30分)\n                    standard_mmse_score = (vr_mmse_score / 21.0) * 30.0\n                    \n                    mmse_data.append({\n                        'subject_id': subject_id,\n                        'vr_mmse_score': int(vr_mmse_score),\n                        'standard_mmse_score': round(standard_mmse_score, 2),\n                        'orientation_time': int(orientation_time),\n                        'orientation_place': int(orientation_place),\n                        'immediate_memory': int(immediate_memory),\n                        'attention_calculation': int(attention_calculation),\n                        'delayed_recall': int(delayed_recall)\n                    })\n                    \n            except Exception as e:\n                logger.error(f\"读取MMSE文件失败 {full_path}: {e}\")\n        \n        mmse_df = pd.DataFrame(mmse_data)\n        logger.info(f\"✅ 提取了 {len(mmse_df)} 个MMSE评分记录\")\n        return mmse_df\n    \n    def calculate_game_sessions(self, subjects_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"计算游戏会话信息\"\"\"\n        logger.info(\"📊 计算游戏会话信息...\")\n        \n        sessions = []\n        \n        # 扫描所有校准数据文件\n        groups = ['ad_calibrated', 'mci_calibrated', 'control_calibrated']\n        \n        for group_dir in groups:\n            group_path = os.path.join(self.data_root, group_dir)\n            if not os.path.exists(group_path):\n                continue\n            \n            for group_folder in os.listdir(group_path):\n                folder_path = os.path.join(group_path, group_folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                \n                for file_name in os.listdir(folder_path):\n                    if not file_name.endswith('_preprocessed_calibrated.csv'):\n                        continue\n                    \n                    file_path = os.path.join(folder_path, file_name)\n                    \n                    try:\n                        # 从文件名提取session_id\n                        session_id = file_name.replace('_preprocessed_calibrated.csv', '')\n                        \n                        # 提取subject_id和task_id\n                        if session_id.startswith('ad'):\n                            subject_id = session_id[:4]  # ad01, ad02, etc.\n                            task_num = session_id[4:]\n                        elif session_id.startswith('m'):\n                            subject_id = session_id[:3]   # m01, m02, etc.\n                            task_num = session_id[3:]\n                        elif session_id.startswith('n'):\n                            subject_id = session_id[:3]   # n01, n02, etc.\n                            task_num = session_id[3:]\n                        else:\n                            continue\n                        \n                        task_id = f'Q{task_num.replace(\"q\", \"\")}'\n                        \n                        # 读取数据文件计算时长\n                        df = pd.read_csv(file_path)\n                        if 'milliseconds' in df.columns and len(df) > 0:\n                            duration_ms = df['milliseconds'].max() - df['milliseconds'].min()\n                            duration_s = duration_ms / 1000.0\n                            \n                            # 归一化游戏时长\n                            duration_norm = self.normalize_value(duration_s, 'game_duration')\n                            \n                            sessions.append({\n                                'session_id': session_id,\n                                'subject_id': subject_id,\n                                'task_id': task_id,\n                                'game_duration_seconds': round(duration_s, 2),\n                                'game_duration_normalized': round(duration_norm, 4),\n                                'data_points_count': len(df),\n                                'file_path': file_path.replace(self.data_root + os.sep, '')\n                            })\n                            \n                    except Exception as e:\n                        logger.warning(f\"处理会话文件失败 {file_path}: {e}\")\n        \n        sessions_df = pd.DataFrame(sessions)\n        sessions_df = sessions_df.sort_values(['subject_id', 'task_id'])\n        \n        logger.info(f\"✅ 计算了 {len(sessions_df)} 个游戏会话\")\n        return sessions_df\n    \n    def aggregate_roi_features(self, sessions_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"聚合ROI特征\"\"\"\n        logger.info(\"📊 聚合ROI特征...\")\n        \n        roi_file = os.path.join(self.data_root, 'event_analysis_results', 'All_ROI_Summary.csv')\n        if not os.path.exists(roi_file):\n            logger.warning(f\"ROI文件不存在: {roi_file}\")\n            return pd.DataFrame()\n        \n        try:\n            roi_df = pd.read_csv(roi_file)\n            \n            roi_features = []\n            \n            # 创建session_id到时长的映射\n            session_durations = dict(zip(sessions_df['session_id'], sessions_df['game_duration_seconds']))\n            \n            for session_id in sessions_df['session_id'].unique():\n                session_data = roi_df[roi_df['ADQ_ID'] == session_id]\n                game_duration = session_durations.get(session_id, 1.0)\n                \n                # 按ROI类型聚合\n                roi_types = ['KW', 'INST', 'BG']\n                \n                for roi_type in roi_types:\n                    roi_type_data = session_data[session_data['ROI'].str.contains(roi_type, na=False)]\n                    \n                    if len(roi_type_data) > 0:\n                        total_fixation_time = roi_type_data['FixTime'].sum()\n                        total_enter_count = roi_type_data['EnterCount'].sum()\n                        total_regression_count = roi_type_data['RegressionCount'].sum()\n                    else:\n                        total_fixation_time = 0.0\n                        total_enter_count = 0\n                        total_regression_count = 0\n                    \n                    # 计算时间占比\n                    fixation_time_percentage = total_fixation_time / game_duration if game_duration > 0 else 0.0\n                    fixation_time_percentage = min(fixation_time_percentage, 1.0)  # 限制在100%以内\n                    \n                    # 归一化\n                    total_fixation_time_norm = self.normalize_value(total_fixation_time, 'roi_fixation_time')\n                    fixation_time_percentage_norm = fixation_time_percentage  # 已经是0-1范围\n                    \n                    roi_features.append({\n                        'session_id': session_id,\n                        'roi_type': roi_type,\n                        'total_fixation_time_seconds': round(total_fixation_time, 3),\n                        'total_fixation_time_normalized': round(total_fixation_time_norm, 4),\n                        'fixation_time_percentage': round(fixation_time_percentage, 4),\n                        'fixation_time_percentage_normalized': round(fixation_time_percentage_norm, 4),\n                        'enter_count': int(total_enter_count),\n                        'regression_count': int(total_regression_count)\n                    })\n            \n            roi_features_df = pd.DataFrame(roi_features)\n            logger.info(f\"✅ 聚合了 {len(roi_features_df)} 个ROI特征记录\")\n            return roi_features_df\n            \n        except Exception as e:\n            logger.error(f\"聚合ROI特征失败: {e}\")\n            return pd.DataFrame()\n    \n    def normalize_rqa_features(self, sessions_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"归一化RQA特征\"\"\"\n        logger.info(\"📊 归一化RQA特征...\")\n        \n        rqa_path = os.path.join(self.data_root, 'rqa_pipeline_results', 'm2_tau1_eps0.055_lmin2', 'step1_rqa_calculation')\n        if not os.path.exists(rqa_path):\n            logger.warning(f\"RQA路径不存在: {rqa_path}\")\n            return pd.DataFrame()\n        \n        try:\n            # 读取所有RQA文件\n            all_rqa_data = []\n            for group in ['ad', 'control', 'mci']:\n                file_path = os.path.join(rqa_path, f'RQA_1D2D_summary_{group}.csv')\n                if os.path.exists(file_path):\n                    df = pd.read_csv(file_path)\n                    df['group'] = group\n                    all_rqa_data.append(df)\n            \n            if not all_rqa_data:\n                logger.warning(\"未找到有效的RQA数据\")\n                return pd.DataFrame()\n            \n            combined_rqa_df = pd.concat(all_rqa_data, ignore_index=True)\n            \n            rqa_features = []\n            \n            for _, row in combined_rqa_df.iterrows():\n                filename = row['filename']\n                session_id = filename.replace('_preprocessed_calibrated.csv', '')\n                \n                # 检查session_id是否在会话列表中\n                if session_id not in sessions_df['session_id'].values:\n                    continue\n                \n                # 原始值\n                rr_2d_xy = row.get('RR-2D-xy', 0.0)\n                rr_1d_x = row.get('RR-1D-x', 0.0)\n                det_2d_xy = row.get('DET-2D-xy', 0.0)\n                det_1d_x = row.get('DET-1D-x', 0.0)\n                ent_2d_xy = row.get('ENT-2D-xy', 0.0)\n                ent_1d_x = row.get('ENT-1D-x', 0.0)\n                \n                # 归一化\n                rr_2d_xy_norm = self.normalize_value(rr_2d_xy, 'RR-2D-xy')\n                rr_1d_x_norm = self.normalize_value(rr_1d_x, 'RR-1D-x')\n                det_2d_xy_norm = self.normalize_value(det_2d_xy, 'DET-2D-xy')\n                det_1d_x_norm = self.normalize_value(det_1d_x, 'DET-1D-x')\n                ent_2d_xy_norm = self.normalize_value(ent_2d_xy, 'ENT-2D-xy')\n                ent_1d_x_norm = self.normalize_value(ent_1d_x, 'ENT-1D-x')\n                \n                rqa_features.append({\n                    'session_id': session_id,\n                    'rr_2d_xy': round(rr_2d_xy, 6),\n                    'rr_2d_xy_normalized': round(rr_2d_xy_norm, 4),\n                    'rr_1d_x': round(rr_1d_x, 6),\n                    'rr_1d_x_normalized': round(rr_1d_x_norm, 4),\n                    'det_2d_xy': round(det_2d_xy, 6),\n                    'det_2d_xy_normalized': round(det_2d_xy_norm, 4),\n                    'det_1d_x': round(det_1d_x, 6),\n                    'det_1d_x_normalized': round(det_1d_x_norm, 4),\n                    'ent_2d_xy': round(ent_2d_xy, 6),\n                    'ent_2d_xy_normalized': round(ent_2d_xy_norm, 4),\n                    'ent_1d_x': round(ent_1d_x, 6),\n                    'ent_1d_x_normalized': round(ent_1d_x_norm, 4)\n                })\n            \n            rqa_features_df = pd.DataFrame(rqa_features)\n            logger.info(f\"✅ 归一化了 {len(rqa_features_df)} 个RQA特征记录\")\n            return rqa_features_df\n            \n        except Exception as e:\n            logger.error(f\"归一化RQA特征失败: {e}\")\n            return pd.DataFrame()\n    \n    def generate_summary_table(self, sessions_df: pd.DataFrame, roi_features_df: pd.DataFrame, \n                             rqa_features_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"生成归一化特征汇总表\"\"\"\n        logger.info(\"📊 生成归一化特征汇总表...\")\n        \n        summary_data = []\n        \n        for _, session in sessions_df.iterrows():\n            session_id = session['session_id']\n            subject_id = session['subject_id']\n            task_id = session['task_id']\n            \n            # 从subject_id推断group_type\n            if subject_id.startswith('ad'):\n                group_type = 'ad'\n            elif subject_id.startswith('m'):\n                group_type = 'mci'\n            elif subject_id.startswith('n'):\n                group_type = 'control'\n            else:\n                group_type = 'unknown'\n            \n            # 初始化汇总记录\n            summary_record = {\n                'session_id': session_id,\n                'subject_id': subject_id,\n                'task_id': task_id,\n                'group_type': group_type,\n                'game_duration_norm': session['game_duration_normalized']\n            }\n            \n            # 添加ROI特征\n            session_roi = roi_features_df[roi_features_df['session_id'] == session_id]\n            for roi_type in ['KW', 'INST', 'BG']:\n                roi_data = session_roi[session_roi['roi_type'] == roi_type]\n                if len(roi_data) > 0:\n                    summary_record[f'roi_{roi_type.lower()}_time_norm'] = roi_data.iloc[0]['total_fixation_time_normalized']\n                    summary_record[f'roi_{roi_type.lower()}_percentage_norm'] = roi_data.iloc[0]['fixation_time_percentage_normalized']\n                else:\n                    summary_record[f'roi_{roi_type.lower()}_time_norm'] = 0.0\n                    summary_record[f'roi_{roi_type.lower()}_percentage_norm'] = 0.0\n            \n            # 添加RQA特征\n            session_rqa = rqa_features_df[rqa_features_df['session_id'] == session_id]\n            if len(session_rqa) > 0:\n                rqa_data = session_rqa.iloc[0]\n                summary_record.update({\n                    'rr_2d_norm': rqa_data['rr_2d_xy_normalized'],\n                    'rr_1d_norm': rqa_data['rr_1d_x_normalized'],\n                    'det_2d_norm': rqa_data['det_2d_xy_normalized'],\n                    'det_1d_norm': rqa_data['det_1d_x_normalized'],\n                    'ent_2d_norm': rqa_data['ent_2d_xy_normalized'],\n                    'ent_1d_norm': rqa_data['ent_1d_x_normalized']\n                })\n            else:\n                summary_record.update({\n                    'rr_2d_norm': 0.0,\n                    'rr_1d_norm': 0.0,\n                    'det_2d_norm': 0.0,\n                    'det_1d_norm': 0.0,\n                    'ent_2d_norm': 0.0,\n                    'ent_1d_norm': 0.0\n                })\n            \n            summary_data.append(summary_record)\n        \n        summary_df = pd.DataFrame(summary_data)\n        summary_df = summary_df.sort_values(['group_type', 'subject_id', 'task_id'])\n        \n        logger.info(f\"✅ 生成了 {len(summary_df)} 个汇总记录\")\n        return summary_df\n    \n    def save_all_tables(self, subjects_df: pd.DataFrame, tasks_df: pd.DataFrame, \n                       mmse_df: pd.DataFrame, sessions_df: pd.DataFrame,\n                       roi_features_df: pd.DataFrame, rqa_features_df: pd.DataFrame,\n                       summary_df: pd.DataFrame):\n        \"\"\"保存所有表格\"\"\"\n        logger.info(\"💾 保存所有表格...\")\n        \n        tables = {\n            'subjects.csv': subjects_df,\n            'tasks.csv': tasks_df,\n            'mmse_scores.csv': mmse_df,\n            'game_sessions.csv': sessions_df,\n            'roi_features.csv': roi_features_df,\n            'rqa_features.csv': rqa_features_df,\n            'normalized_features_summary.csv': summary_df\n        }\n        \n        for filename, df in tables.items():\n            if df is not None and not df.empty:\n                output_path = os.path.join(self.output_dir, filename)\n                df.to_csv(output_path, index=False, encoding='utf-8')\n                logger.info(f\"✅ 保存 {filename}: {len(df)} 行\")\n            else:\n                logger.warning(f\"⚠️ 跳过空表格: {filename}\")\n    \n    def run_full_normalization(self):\n        \"\"\"运行完整的归一化流程\"\"\"\n        logger.info(\"🚀 开始完整的特征归一化流程...\")\n        \n        try:\n            # 1. 提取受试者信息\n            subjects_df = self.extract_subjects_info()\n            \n            # 2. 创建任务信息\n            tasks_df = self.create_tasks_info()\n            \n            # 3. 提取MMSE评分\n            mmse_df = self.extract_mmse_scores()\n            \n            # 4. 计算游戏会话\n            sessions_df = self.calculate_game_sessions(subjects_df)\n            \n            # 5. 聚合ROI特征\n            roi_features_df = self.aggregate_roi_features(sessions_df)\n            \n            # 6. 归一化RQA特征\n            rqa_features_df = self.normalize_rqa_features(sessions_df)\n            \n            # 7. 生成汇总表\n            summary_df = self.generate_summary_table(sessions_df, roi_features_df, rqa_features_df)\n            \n            # 8. 保存所有表格\n            self.save_all_tables(subjects_df, tasks_df, mmse_df, sessions_df,\n                                roi_features_df, rqa_features_df, summary_df)\n            \n            # 9. 生成统计报告\n            self.generate_statistics_report(summary_df)\n            \n            logger.info(\"🎉 归一化流程完成！\")\n            \n        except Exception as e:\n            logger.error(f\"❌ 归一化流程失败: {e}\")\n            raise\n    \n    def generate_statistics_report(self, summary_df: pd.DataFrame):\n        \"\"\"生成统计报告\"\"\"\n        logger.info(\"📊 生成统计报告...\")\n        \n        try:\n            report = []\n            report.append(\"# 归一化特征统计报告\\n\")\n            report.append(f\"生成时间: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n            report.append(f\"总会话数: {len(summary_df)}\\n\")\n            \n            # 按组统计\n            report.append(\"\\n## 按实验组统计\\n\")\n            group_stats = summary_df.groupby('group_type').size()\n            for group, count in group_stats.items():\n                report.append(f\"- {group}: {count} 个会话\")\n            \n            # 按任务统计\n            report.append(\"\\n\\n## 按任务统计\\n\")\n            task_stats = summary_df.groupby('task_id').size()\n            for task, count in task_stats.items():\n                report.append(f\"- {task}: {count} 个会话\")\n            \n            # 特征统计\n            report.append(\"\\n\\n## 归一化特征统计\\n\")\n            numeric_cols = [col for col in summary_df.columns if col.endswith('_norm')]\n            feature_stats = summary_df[numeric_cols].describe()\n            \n            for col in numeric_cols:\n                stats = feature_stats[col]\n                report.append(f\"\\n### {col}\")\n                report.append(f\"- 均值: {stats['mean']:.4f}\")\n                report.append(f\"- 标准差: {stats['std']:.4f}\")\n                report.append(f\"- 最小值: {stats['min']:.4f}\")\n                report.append(f\"- 最大值: {stats['max']:.4f}\")\n            \n            # 保存报告\n            report_content = \"\\n\".join(report)\n            report_path = os.path.join(self.output_dir, 'statistics_report.md')\n            with open(report_path, 'w', encoding='utf-8') as f:\n                f.write(report_content)\n            \n            logger.info(f\"✅ 统计报告已保存: {report_path}\")\n            \n        except Exception as e:\n            logger.error(f\"生成统计报告失败: {e}\")\n\ndef main():\n    \"\"\"主函数\"\"\"\n    normalizer = FeatureNormalizer()\n    normalizer.run_full_normalization()\n    \n    print(\"\\n🎉 特征归一化完成！\")\n    print(\"📁 输出文件位置: data/normalized_features/\")\n    print(\"📊 生成的表格:\")\n    print(\"   - subjects.csv: 受试者基本信息\")\n    print(\"   - tasks.csv: 任务信息\")\n    print(\"   - mmse_scores.csv: MMSE评分\")\n    print(\"   - game_sessions.csv: 游戏会话信息\")\n    print(\"   - roi_features.csv: ROI特征\")\n    print(\"   - rqa_features.csv: RQA特征\")\n    print(\"   - normalized_features_summary.csv: 归一化特征汇总\")\n    print(\"   - statistics_report.md: 统计报告\")\n\nif __name__ == \"__main__\":\n    main()